{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95933942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import requests\n",
    "from os import makedirs, path, listdir, remove\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import zipfile as zpf\n",
    "from shutil import rmtree\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import squareform, pdist, cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "\n",
    "import httplib2\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f834e",
   "metadata": {},
   "source": [
    "### Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797754ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_map(data_geodataframe, map_geodataframe, \n",
    "                data_column=None, map_column=None, \n",
    "                data_cmap=None, map_cmap=None, \n",
    "                data_color=None, map_color=\"whitesmoke\", \n",
    "                data_markersize=0.1, \n",
    "                map_edge_color=\"black\", \n",
    "                colorbar=False, \n",
    "                title=\"Greater London\", \n",
    "                fontsize=\"25\", \n",
    "                figsize=(20,10), \n",
    "                axis=\"off\",\n",
    "                mark=None):\n",
    "    \n",
    "    base = data_geodataframe.plot(column=data_column, \n",
    "                           ax=map_geodataframe.plot(column=map_column, \n",
    "                                                    figsize=figsize, \n",
    "                                                    color=map_color, \n",
    "                                                    edgecolor=map_edge_color, \n",
    "                                                    cmap=map_cmap), \n",
    "                           color=data_color, cmap=data_cmap, markersize=data_markersize)\n",
    "    if colorbar:\n",
    "        colorbar_max = data_geodataframe[data_column].max()\n",
    "        norm = plt.Normalize(data_geodataframe[data_column].min(), colorbar_max)\n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap=data_cmap, \n",
    "        norm=norm)).set_label(data_column)\n",
    "        \n",
    "    if mark:\n",
    "        marked = data_geodataframe[data_geodataframe['@SiteCode'] == mark]\n",
    "        marked.plot(ax=base, marker='x', color='black', markersize=15);\n",
    "    \n",
    "    plt.suptitle(title, fontsize=fontsize)\n",
    "    plt.xlabel('Longitude', fontsize=14)\n",
    "    plt.ylabel('Latitude', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.axis(axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be44a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_osm_map(data_geodataframe, map_geodataframe, cmap, figsize=(20,10), colorbar=False, data_column='Similarity', title='LAQN Monitoring Station Distribution', mark=None, similars=None):\n",
    "    \n",
    "    base = data_geodataframe.plot(ax=map_geodataframe.plot(figsize=figsize, \n",
    "                                           column='fclass',\n",
    "                                           legend=False,\n",
    "                                           cmap=cmap,\n",
    "                                           alpha=0.5,\n",
    "                                           legend_kwds={'loc': 'center right', 'bbox_to_anchor':(1.3,0.5)}),\n",
    "                    color='black', marker='x', markersize=75, linewidths=3)\n",
    "    \n",
    "    if colorbar:\n",
    "        colorbar_max = data_geodataframe[data_column].max()\n",
    "        norm = plt.Normalize(data_geodataframe[data_column].min(), colorbar_max)\n",
    "        plt.colorbar(plt.cm.ScalarMappable(cmap=None, \n",
    "        norm=norm)).set_label(data_column)\n",
    "        \n",
    "    if mark:\n",
    "        marked = data_geodataframe[data_geodataframe['@SiteCode'] == mark]\n",
    "        marked.plot(ax=base, marker='o', color='black', markersize=100);\n",
    "\n",
    "    if mark and similar:\n",
    "        title = f'{title}\\n Similar stations: {similars}'\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20)\n",
    "    plt.xlabel('Longitude', fontsize=14)\n",
    "    plt.ylabel('Latitude', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.axis(\"on\")\n",
    "    plt.savefig(f'images/{mark}_similarity.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbeb8c",
   "metadata": {},
   "source": [
    "### Graph Adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.orig = self.df.copy()\n",
    "        self.df['date'] = pd.to_datetime(self.df.date)\n",
    "        \n",
    "    def drop_null(self, nan_percent):\n",
    "        # drop column if proportion of NaN elements exceed the nan_percent\n",
    "        min_count = int(((100-nan_percent)/100)*self.df.shape[0] + 1)\n",
    "        return self.df.dropna(axis=1, thresh=min_count) \n",
    "        \n",
    "    def fill_mean(self):\n",
    "        return self.df.fillna(self.df.mean())\n",
    "    \n",
    "    def group(self, freq):\n",
    "        # group the data by the specified freq (month/year) and average across this period, then fill NaN values \n",
    "        df = self.df.groupby(pd.Grouper(key=\"date\", freq=freq)).mean()\n",
    "        return df\n",
    "    \n",
    "    def group_and_fill(self, freq):\n",
    "        # group the data by the specified freq (month/year) and average across this period, then fill NaN values \n",
    "        df = self.df.groupby(pd.Grouper(key=\"date\", freq=freq)).mean()\n",
    "        return df.ffill().bfill()\n",
    "    \n",
    "    def fill(self):\n",
    "        df = self.df.copy()\n",
    "        for col in df.columns.drop('date'):\n",
    "            df[col] = df[col].fillna(df.groupby([df.date.dt.year, df.date.dt.month])[col].transform('mean'))\n",
    "        return df.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeAM():\n",
    "    def __init__(self, df):\n",
    "        am_shape = (df.shape[1], df.shape[1])\n",
    "        self.am = pd.DataFrame(np.zeros(shape=am_shape), columns=df.columns, index=df.columns)\n",
    "    \n",
    "    def euclidean_dist(self, df):\n",
    "        # np.linalg.norm(complete['TD0'].values - complete['BG3'].values) #test euclidean distance between two columns\n",
    "        dist_arr = squareform(pdist(df.transpose()))\n",
    "        return pd.DataFrame(dist_arr, columns=df.columns.unique(), index=df.columns.unique())\n",
    "    \n",
    "    def cosine_dist(self, df):\n",
    "        dist_arr = cosine_similarity(df.transpose())\n",
    "        np.fill_diagonal(dist_arr, 0)\n",
    "        return pd.DataFrame(dist_arr, columns=df.columns.unique(), index=df.columns.unique())\n",
    "    \n",
    "    def threshold_euclidean(self, df, threshold):\n",
    "        for col in df.columns:\n",
    "#             df.loc[df[col] > threshold, col] = 0\n",
    "#             df.loc[df[col] < threshold, col] = 1\n",
    "            df[col] = np.where(df[col]>=threshold, 0, 1)\n",
    "        np.fill_diagonal(df.values, 0)\n",
    "        return df\n",
    "    \n",
    "    def diagonal_degree(self, df):\n",
    "        diag_series = np.diag(df.sum())\n",
    "        degree_mat = pd.DataFrame(diag_series, columns=df.columns.unique(), index=df.columns.unique())\n",
    "        return degree_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7eb8b3",
   "metadata": {},
   "source": [
    "### Create Control Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52212e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set(df, num_valid_values=500):\n",
    "    max_size = 0\n",
    "    max_index = 0\n",
    "\n",
    "    for i in range(0, df.shape[0], 5):\n",
    "        test = df.iloc[i:].isnull()\n",
    "        test.reset_index(drop=True, inplace=True)\n",
    "        res = test.eq(True).idxmax()\n",
    "        size = res[res > num_valid_values].size\n",
    "        if size > max_size:\n",
    "            max_size = size\n",
    "            max_index = i\n",
    "\n",
    "    test = df.iloc[max_index:].isnull()\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    res = test.eq(True).idxmax()\n",
    "    max_cols = res[res > num_valid_values].keys()\n",
    "    test_set = df[max_cols].iloc[max_index:max_index+num_valid_values]\n",
    "    return test_set, max_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981572b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_gaps(test_set, proportion=0.25, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    testing = test_set.copy()\n",
    "    \n",
    "    num_gaps = int(proportion * test_set.size)\n",
    "\n",
    "    # Replace random entries with NaNs\n",
    "    num_entries = test_set.size\n",
    "    nan_indices = np.random.choice(np.arange(num_entries), num_gaps, replace=False)\n",
    "    nan_entries = [(num // test_set.shape[1], num % test_set.shape[1]) for num in nan_indices]\n",
    "\n",
    "    initial = []\n",
    "    for entry in nan_entries:\n",
    "        initial.append(testing.iloc[entry])\n",
    "        testing.iloc[entry] = np.nan\n",
    "    return nan_entries, initial, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00172f",
   "metadata": {},
   "source": [
    "### Graph Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd60b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPropagation():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def threshold_am(self, df, threshold):\n",
    "        result = df.copy()\n",
    "        for col in result.columns:\n",
    "#             df.loc[df[col] > threshold, col] = 0\n",
    "#             df.loc[df[col] < threshold, col] = 1\n",
    "            result[col] = np.where(result[col] >= threshold, 1, 0)\n",
    "        np.fill_diagonal(result.values, 1)\n",
    "        return result\n",
    "    \n",
    "    def diagonal_degree(self, df):\n",
    "        diag_series = np.diag(df.sum())\n",
    "        result = pd.DataFrame(diag_series, columns=df.columns.unique(), index=df.columns.unique())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH PROPAGATION ALGORITHM\n",
    "\n",
    "def D_pow(mat, power):\n",
    "    return scipy.linalg.fractional_matrix_power(mat, power)\n",
    "\n",
    "def basic_graph_propagation(X, A, w, L, a=0.5, b=0.5):\n",
    "    D_list = np.sum(A, axis=1) # D matrix\n",
    "    w = np.array(w) \n",
    "    prop_matrix = np.diag(D_list**-a).dot(A).dot(np.diag(D_list**-b)) # DAD^(-1)\n",
    "    prop_matrix = np.nan_to_num(prop_matrix) # convert NaNs to 0s\n",
    "    \n",
    "    pi = np.zeros_like(X)\n",
    "    r = X\n",
    "    for i in range(L):\n",
    "        Y_i = w[i:].sum()\n",
    "        Y_iplus = w[i+1:].sum()\n",
    "        \n",
    "        # update pi estimate\n",
    "        q = (w[i]/Y_i) * r\n",
    "        pi += q\n",
    "        \n",
    "        # update r\n",
    "        r = (Y_i/Y_iplus) * prop_matrix.dot(r.T).T\n",
    "        \n",
    "    q = w[L]/w[L:].sum() * r\n",
    "    pi += q\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fff164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_refactor(gap_data):\n",
    "    filled_data = gap_data.ffill().bfill()\n",
    "    am = ComputeAM(filled_data)\n",
    "    euclidean_am = am.euclidean_dist(filled_data) # initially, the larger the value, the more distant and the less similar\n",
    "\n",
    "    mean = euclidean_am.mean().mean() \n",
    "    refactored = (mean / euclidean_am)  # Larger values represent more similar stations\n",
    "    np.fill_diagonal(refactored.values, 0)\n",
    "    return filled_data, refactored\n",
    "\n",
    "def get_L(matrix):\n",
    "    total = np.zeros_like(matrix)\n",
    "    \n",
    "    i = 0\n",
    "    while np.count_nonzero(total) != matrix.size:\n",
    "        i += 1\n",
    "        total += np.linalg.matrix_power(matrix, i)\n",
    "        if i == 10:\n",
    "            break\n",
    "    return i\n",
    "\n",
    "def compute_progation_matrix(data, euclideans, threshold, L=None, alpha=None, w=np.array([1, 0, 0, 0])):\n",
    "    prop = GraphPropagation()\n",
    "    A = prop.threshold_am(euclideans, threshold)\n",
    "\n",
    "    if alpha:\n",
    "        w = [alpha*(1-alpha)**i for i in range(10)]\n",
    "    if not L:\n",
    "        L = get_L(A)\n",
    "\n",
    "    # Apply algorithm\n",
    "    array_data = data.to_numpy()\n",
    "    Z = basic_graph_propagation(array_data, A, w, L)\n",
    "    return Z, A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19980957",
   "metadata": {},
   "source": [
    "### Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_error(initial, final):\n",
    "    return np.linalg.norm(np.array(initial) - np.array(final)) / len(initial)**0.5\n",
    "\n",
    "def smape_error(initial, final):\n",
    "    initial, final = np.array(initial), np.array(final)\n",
    "    num = np.absolute(initial - final)\n",
    "    den = (np.absolute(initial) + np.absolute(final)) / 2\n",
    "    elems = num/den\n",
    "    return np.sum(elems) / elems.size\n",
    "\n",
    "def compute_error(alpha, threshold, L, initial, nan_entries, data, euclideans, error_type='rmse'):\n",
    "    prop = GraphPropagation()\n",
    "    A = prop.threshold_am(euclideans, threshold)\n",
    "    w = [alpha*(1-alpha)**i for i in range(10)]\n",
    "\n",
    "    # Apply algorithm\n",
    "    array_data = data.to_numpy()\n",
    "    Z = basic_graph_propagation(array_data, A, w, L)\n",
    "    \n",
    "    final = []\n",
    "    for entry in nan_entries:\n",
    "        final.append(Z[entry])\n",
    "    \n",
    "    if error_type == 'rmse':\n",
    "        error = rmse_error(initial, final)\n",
    "    elif error_type == 'smape':\n",
    "        error = smape_error(initial, final)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9daaf3",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_count(df):\n",
    "    grouped_M = group_dataframe2(df, 'M')\n",
    "    res = pd.DataFrame(index=grouped_M.index, columns=grouped_M.columns)\n",
    "    \n",
    "    stations = df.columns.tolist()\n",
    "    test = df.reset_index(level=0)\n",
    "    \n",
    "    i = 0\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            sample_df = test[(test['date'].dt.year == year) & (test['date'].dt.month == month)]\n",
    "            res.iloc[i] = sample_df.isna().sum().tolist()[1:]\n",
    "            i += 1\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_missing_dates(df, station):\n",
    "    station_data = df[station]\n",
    "    grouped_missing = station_data[station_data.isnull()]\n",
    "    grouped_missing.iloc[:] = 1.0\n",
    "    grouped_M_missing = group_dataframe2(grouped_missing, 'M')\n",
    "    test = grouped_M_missing.reset_index(level=0)\n",
    "    missing_dates = test[test[station] == 1.0]['date'].tolist()\n",
    "    return missing_dates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
